{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZXL5w3vyof0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "data_info_train = pd.read_csv('personal_info_train.csv')\n",
        "data_meas_train = pd.read_csv('measurements_results_train.csv')\n",
        "data_info_test = pd.read_csv('personal_info_test.csv')\n",
        "data_meas_test = pd.read_csv('measurements_results_test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uB7-_8dD75P-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VnXLTI22lDvQ"
      },
      "outputs": [],
      "source": [
        "#We will fill in our measurements data using an interpolation function\n",
        "\n",
        "\n",
        "data_meas_train.interpolate(inplace =True)\n",
        "data_meas_test.interpolate(inplace =True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DF7UKwD7yqg3"
      },
      "outputs": [],
      "source": [
        "#We will fill in our information data using an interpolation function\n",
        "\n",
        "data_info_train.interpolate(inplace =True)\n",
        "data_info_test.interpolate(inplace =True)\n",
        "meas_features = data_meas_train.columns.to_list()[1::]\n",
        "\n",
        "\n",
        "#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3AnLDZV0yqlz"
      },
      "outputs": [],
      "source": [
        "\n",
        "#We will merge the two train data frames together\n",
        "data_info_train = data_info_train.merge(data_meas_train, how='inner',on=None, left_on=None, right_on=None, left_index=False, right_index=False)\n",
        "#We will merge the two test data frames together\n",
        "data_info_test = data_info_test.merge(data_meas_test, how='inner',on=None, left_on=None, right_on=None, left_index=False, right_index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "neIyDG7RzRvO",
        "outputId": "a5b596c7-b31f-4ec2-c192-7ebd0a13503f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    61995\n",
              "1     2793\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "#We will set our target\n",
        "target_train = data_info_train['label']\n",
        "data_info_train.drop('label',axis = 1,inplace= True)\n",
        "\n",
        "###\n",
        "target_test = data_info_test['label']\n",
        "data_info_test.drop('label',axis = 1,inplace= True)\n",
        "target_train.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_wcrIMKm3AC",
        "outputId": "53ef1e1a-9912-4f35-dab4-439f70bd8bee"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    61995\n",
              "1     2793\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "target_train.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tN_hZQwQy1Rn"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "#We will separate the ,'patient_id' feature  into a separate data frame\n",
        "test_ids = data_info_test['patient_id']\n",
        "train_ids = data_info_train['patient_id']\n",
        "\n",
        "# %% [code]\n",
        "data_info_train.drop(['patient_id'],axis= 1, inplace = True)\n",
        "\n",
        "#####\n",
        "data_info_test.drop(['patient_id'],axis= 1, inplace = True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QReaclaPyqai"
      },
      "outputs": [],
      "source": [
        "#Fill in the missing values ​​in the HMO column using the word \"Unknown HMO\"\n",
        "data_info_train['HMO'].fillna('unknown HMO',inplace = True)\n",
        "data_info_test['HMO'].fillna('unknown HMO',inplace = True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VlAXRwuKtrWt"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uIJDBws5y1PO"
      },
      "outputs": [],
      "source": [
        "# %% [code]\n",
        "#e will change the gender column to be coded by numbers and not by letters\n",
        "data_info_train['gender']=data_info_train['gender'].astype('category') #I changed the variable to be a categorical variable\n",
        "data_info_train['gender'].replace(data_info_train['gender'].unique(),[1,0],inplace=True) #Change values to numeric values\n",
        "data_info_train['gender']=data_info_train['gender'].astype(int) #We will change the variable to be a variable of type int\n",
        "\n",
        "date_features = ['created_at','birth_date']\n",
        "\n",
        "#We will change the date columns\n",
        "data_info_train[date_features] = data_info_train[date_features].apply(pd.to_datetime)\n",
        "\n",
        "#########\n",
        "\n",
        "#We will change the gender column to be coded by numbers and not by letters\n",
        "data_info_test['gender']=data_info_test['gender'].astype('category') #I changed the variable to be a categorical variable\n",
        "data_info_test['gender'].replace(data_info_test['gender'].unique(),[1,0],inplace=True) #Change values to numeric values\n",
        "data_info_test['gender']=data_info_test['gender'].astype(int) #We will change the variable to be a variable of type int\n",
        "\n",
        "\n",
        "date_features_test = ['created_at','birth_date']\n",
        "\n",
        "#We will change the date columns\n",
        "data_info_test[date_features] = data_info_test[date_features_test].apply(pd.to_datetime)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i-fkzEXWPWAE"
      },
      "outputs": [],
      "source": [
        "#We will handle the \"gender\" column by encoding it using one hot encoder on our train data\n",
        "\n",
        "\n",
        "#We will make the \"gender\" feature a categorical variable\n",
        "#data_info_train['gender']=data_info_train['gender'].astype('category')\n",
        "#gender_data_train = data_info_train[['gender']]\n",
        "\n",
        "\n",
        "# Initialize the OneHotEncoder\n",
        "#unique_categories = data_info_train['gender'].unique()\n",
        "#encoder_gender1 = OneHotEncoder(sparse = False)\n",
        "\n",
        "# Fit and transform the 'city' data using the encoder\n",
        "#encoded_data_train = encoder_gender1.fit_transform(gender_data_train)\n",
        "#encoded_df_train = pd.DataFrame(encoded_data_train, columns=data_info_train['gender'].unique())\n",
        "\n",
        "# Concatenate the encoded DataFrame with the original DataFrame\n",
        "#data_encoded_train = pd.concat([data_info_train, encoded_df_train], axis=1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#We will handle the \"gender\" column by encoding it using one hot encoder on our test data\n",
        "\n",
        "\n",
        "#We will make the \"gender\" feature a categorical variable\n",
        "#ata_info_test['gender']=data_info_test['gender'].astype('category')\n",
        "#gender_data_test = data_info_test[['gender']]\n",
        "\n",
        "\n",
        "# Initialize the OneHotEncoder\n",
        "#unique_categories = data_info_test['gender'].unique()\n",
        "#encoder_gender2 = OneHotEncoder(sparse = False)\n",
        "\n",
        "\n",
        "# Fit and transform the 'city' data using the encoder\n",
        "#encoded_data_test = encoder_gender2.fit_transform(gender_data_test)\n",
        "#encoded_df_test = pd.DataFrame(encoded_data_test, columns=data_info_test['gender'].unique())\n",
        "\n",
        "\n",
        "# Concatenate the encoded DataFrame with the original DataFrame\n",
        "#data_encoded_test = pd.concat([data_info_test, encoded_df_test], axis=1)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tBMm9oiNQ5J3"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DeNabRZky-4i",
        "outputId": "9e777db3-4830-4794-9a46-27878bc92581"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "#We will handle the \"city\" column by encoding it using one hot encoder on our train data\n",
        "\n",
        "\n",
        "#We will make the \"city\" feature a categorical variable\n",
        "data_info_train['city']=data_info_train['city'].astype('category')\n",
        "city_data_train = data_info_train[['city']]\n",
        "\n",
        "\n",
        "# Initialize the OneHotEncoder\n",
        "unique_categories = data_info_train['city'].unique()\n",
        "encoder = OneHotEncoder(sparse = False)\n",
        "\n",
        "\n",
        "# Fit and transform the 'city' data using the encoder\n",
        "encoded_data_train = encoder.fit_transform(city_data_train)\n",
        "encoded_df_train = pd.DataFrame(encoded_data_train, columns=data_info_train['city'].unique())\n",
        "\n",
        "\n",
        "# Concatenate the encoded DataFrame with the original DataFrame\n",
        "data_encoded_train = pd.concat([data_info_train, encoded_df_train], axis=1)\n",
        "\n",
        "\n",
        "\n",
        "#We will handle the \"gender\" column by encoding it using one hot encoder\n",
        "\n",
        "\n",
        "data_info_test['city']=data_info_test['city'].astype('category')\n",
        "city_data_test = data_info_test[['city']]\n",
        "\n",
        "\n",
        "# Initialize the OneHotEncoder\n",
        "encoder = OneHotEncoder(handle_unknown='ignore',sparse = False)\n",
        "\n",
        "\n",
        "# Fit and transform the 'city' data using the encoder\n",
        "encoded_data_test = encoder.fit_transform(city_data_test)\n",
        "encoded_df_test = pd.DataFrame(encoded_data_test, columns= data_info_train['city'].unique())\n",
        "\n",
        "\n",
        "# Concatenate the encoded DataFrame with the original DataFrame\n",
        "data_encoded_test = pd.concat([data_info_test, encoded_df_test], axis=1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sbMctxjrzHfR",
        "outputId": "077d4dd1-ae8b-451b-e645-865111a9b072"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "#We will handle the \"city\" column by encoding it using one hot encoder on our train data\n",
        "\n",
        "\n",
        "#We will make the \"HMO\" feature a categorical variable\n",
        "data_info_train['HMO']=data_info_train['HMO'].astype('category')\n",
        "HMO_data_train = data_info_train[['HMO']]\n",
        "\n",
        "# Initialize the OneHotEncoder\n",
        "encoder_HMO_train = OneHotEncoder(sparse= False )\n",
        "\n",
        "# Fit and transform the 'city' data using the encoder\n",
        "encoded_data_HMO_train = encoder_HMO_train.fit_transform(HMO_data_train)\n",
        "\n",
        "\n",
        "encoded_df_HMO_train = pd.DataFrame(encoded_data_HMO_train, columns= data_encoded_train['HMO'].unique())\n",
        "\n",
        "# Concatenate the encoded DataFrame with the original DataFrame\n",
        "data_encoded_train = pd.concat([data_encoded_train, encoded_df_HMO_train], axis=1)\n",
        "\n",
        "\n",
        "#####\n",
        "\n",
        "\n",
        "#We will make the \"HMO\" feature a categorical variable\n",
        "data_info_train['HMO']=data_info_train['HMO'].astype('category')\n",
        "HMO_data_test = data_info_test[['HMO']]\n",
        "\n",
        "# Initialize the OneHotEncoder\n",
        "encoder_HMO_test = OneHotEncoder(handle_unknown='ignore',sparse=False)\n",
        "\n",
        "# Fit and transform the 'city' data using the encoder\n",
        "encoded_data_HMO_test = encoder_HMO_test.fit_transform(HMO_data_test)\n",
        "encoded_df_HMO_test = pd.DataFrame(encoded_data_HMO_test, columns= data_encoded_train['HMO'].unique())\n",
        "\n",
        "# Concatenate the encoded DataFrame with the original DataFrame\n",
        "data_encoded_test = pd.concat([data_encoded_test, encoded_df_HMO_test], axis=1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gKmff8_izKa3"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "#Calculate the distance in years from the date of birth to today's date\n",
        "\n",
        "\n",
        "\n",
        "reference_point = pd.to_datetime('today')\n",
        "\n",
        "data_encoded_train['age'] = (reference_point -data_encoded_train['birth_date'])/pd.Timedelta(days=365.25)\n",
        "data_encoded_train['time in system'] = (reference_point -data_encoded_train['created_at'])/pd.Timedelta(days=365.25)\n",
        "\n",
        "\n",
        "data_encoded_train.drop(['birth_date','created_at'],axis= 1 , inplace = True)\n",
        "########\n",
        "\n",
        "\n",
        "\n",
        "#Calculate the distance in years from the date of  to today's date\n",
        "\n",
        "# Step 2: Define your reference point\n",
        "reference_point_ = pd.to_datetime('2023-06-16')\n",
        "\n",
        "# Step 3: Calculate time duration since reference point\n",
        "data_encoded_test['age'] = (reference_point -data_encoded_test['birth_date'])/pd.Timedelta(days=365.25)\n",
        "data_encoded_test['time in system'] = (reference_point -data_encoded_test['created_at'])/pd.Timedelta(days=365.25)\n",
        "\n",
        "\n",
        "data_encoded_test.drop(['birth_date','created_at'],axis= 1 , inplace = True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cwuxzRkwMDeh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IW4qFb_ozKdB"
      },
      "outputs": [],
      "source": [
        "\n",
        "# %% [code]\n",
        "data_encoded_train.drop(['city','HMO','region','country'],axis= 1, inplace = True)\n",
        "\n",
        "#####\n",
        "data_encoded_test.drop(['city','HMO','region','country'],axis= 1, inplace = True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8CDbi-FwVBA",
        "outputId": "ac58c14f-3045-4e79-a50a-0b59b3db2835"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 15947 entries, 0 to 15946\n",
            "Data columns (total 54 columns):\n",
            " #   Column          Non-Null Count  Dtype  \n",
            "---  ------          --------------  -----  \n",
            " 0   gender          15947 non-null  int64  \n",
            " 1   height          15947 non-null  float64\n",
            " 2   bmi             15947 non-null  float64\n",
            " 3   heart_rate      15947 non-null  float64\n",
            " 4   steps_day_1     15947 non-null  int64  \n",
            " 5   steps_day_2     15947 non-null  float64\n",
            " 6   steps_day_3     15947 non-null  int64  \n",
            " 7   steps_day_4     15947 non-null  int64  \n",
            " 8   steps_day_5     15947 non-null  int64  \n",
            " 9   employment      15947 non-null  int64  \n",
            " 10  weight          15947 non-null  float64\n",
            " 11  test_0          15947 non-null  float64\n",
            " 12  test_1          15947 non-null  float64\n",
            " 13  test_2          15947 non-null  float64\n",
            " 14  test_3          15947 non-null  float64\n",
            " 15  test_4          15947 non-null  float64\n",
            " 16  test_5          15947 non-null  float64\n",
            " 17  test_6          15947 non-null  float64\n",
            " 18  test_7          15947 non-null  float64\n",
            " 19  test_8          15947 non-null  float64\n",
            " 20  test_9          15947 non-null  float64\n",
            " 21  test_10         15947 non-null  float64\n",
            " 22  test_11         15947 non-null  float64\n",
            " 23  test_12         15947 non-null  float64\n",
            " 24  test_13         15947 non-null  float64\n",
            " 25  test_14         15947 non-null  float64\n",
            " 26  test_15         15947 non-null  float64\n",
            " 27  test_16         15947 non-null  float64\n",
            " 28  test_17         15947 non-null  float64\n",
            " 29  test_18         15947 non-null  float64\n",
            " 30  test_19         15947 non-null  float64\n",
            " 31  Tel Aviv        15947 non-null  float64\n",
            " 32  Ashdod          15947 non-null  float64\n",
            " 33  Givatayim       15947 non-null  float64\n",
            " 34  Yahud           15947 non-null  float64\n",
            " 35  Lod             15947 non-null  float64\n",
            " 36  Or-Yehuda       15947 non-null  float64\n",
            " 37  Yavne           15947 non-null  float64\n",
            " 38  Holon           15947 non-null  float64\n",
            " 39  Jerusalem       15947 non-null  float64\n",
            " 40  Rehovot         15947 non-null  float64\n",
            " 41  Ness-Ziona      15947 non-null  float64\n",
            " 42  Kiriat-Ono      15947 non-null  float64\n",
            " 43  Rishon Lezion   15947 non-null  float64\n",
            " 44  Petah-Tikva     15947 non-null  float64\n",
            " 45  Bat Yam         15947 non-null  float64\n",
            " 46  Ramla           15947 non-null  float64\n",
            " 47  Ramat Gan       15947 non-null  float64\n",
            " 48  unknown HMO     15947 non-null  float64\n",
            " 49  Meuhedet        15947 non-null  float64\n",
            " 50  Maccabi         15947 non-null  float64\n",
            " 51  Clalit          15947 non-null  float64\n",
            " 52  age             15947 non-null  float64\n",
            " 53  time in system  15947 non-null  float64\n",
            "dtypes: float64(48), int64(6)\n",
            "memory usage: 6.7 MB\n"
          ]
        }
      ],
      "source": [
        "data_encoded_test.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vxrKK1-4wfJL",
        "outputId": "abe1bd53-f6ab-4d08-f4c9-a09bd8648fba"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    61995\n",
              "1     2793\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "target_train.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y0dWihyX0olU",
        "outputId": "0c97da4f-0e36-4807-9472-cff4f4f169fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 15947 entries, 0 to 15946\n",
            "Data columns (total 54 columns):\n",
            " #   Column          Non-Null Count  Dtype  \n",
            "---  ------          --------------  -----  \n",
            " 0   gender          15947 non-null  int64  \n",
            " 1   height          15947 non-null  float64\n",
            " 2   bmi             15947 non-null  float64\n",
            " 3   heart_rate      15947 non-null  float64\n",
            " 4   steps_day_1     15947 non-null  int64  \n",
            " 5   steps_day_2     15947 non-null  float64\n",
            " 6   steps_day_3     15947 non-null  int64  \n",
            " 7   steps_day_4     15947 non-null  int64  \n",
            " 8   steps_day_5     15947 non-null  int64  \n",
            " 9   employment      15947 non-null  int64  \n",
            " 10  weight          15947 non-null  float64\n",
            " 11  test_0          15947 non-null  float64\n",
            " 12  test_1          15947 non-null  float64\n",
            " 13  test_2          15947 non-null  float64\n",
            " 14  test_3          15947 non-null  float64\n",
            " 15  test_4          15947 non-null  float64\n",
            " 16  test_5          15947 non-null  float64\n",
            " 17  test_6          15947 non-null  float64\n",
            " 18  test_7          15947 non-null  float64\n",
            " 19  test_8          15947 non-null  float64\n",
            " 20  test_9          15947 non-null  float64\n",
            " 21  test_10         15947 non-null  float64\n",
            " 22  test_11         15947 non-null  float64\n",
            " 23  test_12         15947 non-null  float64\n",
            " 24  test_13         15947 non-null  float64\n",
            " 25  test_14         15947 non-null  float64\n",
            " 26  test_15         15947 non-null  float64\n",
            " 27  test_16         15947 non-null  float64\n",
            " 28  test_17         15947 non-null  float64\n",
            " 29  test_18         15947 non-null  float64\n",
            " 30  test_19         15947 non-null  float64\n",
            " 31  Tel Aviv        15947 non-null  float64\n",
            " 32  Ashdod          15947 non-null  float64\n",
            " 33  Givatayim       15947 non-null  float64\n",
            " 34  Yahud           15947 non-null  float64\n",
            " 35  Lod             15947 non-null  float64\n",
            " 36  Or-Yehuda       15947 non-null  float64\n",
            " 37  Yavne           15947 non-null  float64\n",
            " 38  Holon           15947 non-null  float64\n",
            " 39  Jerusalem       15947 non-null  float64\n",
            " 40  Rehovot         15947 non-null  float64\n",
            " 41  Ness-Ziona      15947 non-null  float64\n",
            " 42  Kiriat-Ono      15947 non-null  float64\n",
            " 43  Rishon Lezion   15947 non-null  float64\n",
            " 44  Petah-Tikva     15947 non-null  float64\n",
            " 45  Bat Yam         15947 non-null  float64\n",
            " 46  Ramla           15947 non-null  float64\n",
            " 47  Ramat Gan       15947 non-null  float64\n",
            " 48  unknown HMO     15947 non-null  float64\n",
            " 49  Meuhedet        15947 non-null  float64\n",
            " 50  Maccabi         15947 non-null  float64\n",
            " 51  Clalit          15947 non-null  float64\n",
            " 52  age             15947 non-null  float64\n",
            " 53  time in system  15947 non-null  float64\n",
            "dtypes: float64(48), int64(6)\n",
            "memory usage: 6.7 MB\n"
          ]
        }
      ],
      "source": [
        "data_encoded_test.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1eyiwyzochT",
        "outputId": "d693b918-bda0-4674-ed2e-770e3ab93af7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 64788 entries, 0 to 64787\n",
            "Data columns (total 54 columns):\n",
            " #   Column          Non-Null Count  Dtype  \n",
            "---  ------          --------------  -----  \n",
            " 0   gender          64788 non-null  int64  \n",
            " 1   height          64788 non-null  float64\n",
            " 2   bmi             64788 non-null  float64\n",
            " 3   heart_rate      64788 non-null  float64\n",
            " 4   steps_day_1     64788 non-null  int64  \n",
            " 5   steps_day_2     64788 non-null  float64\n",
            " 6   steps_day_3     64788 non-null  int64  \n",
            " 7   steps_day_4     64788 non-null  int64  \n",
            " 8   steps_day_5     64788 non-null  int64  \n",
            " 9   employment      64788 non-null  int64  \n",
            " 10  weight          64788 non-null  float64\n",
            " 11  test_0          64788 non-null  float64\n",
            " 12  test_1          64788 non-null  float64\n",
            " 13  test_2          64788 non-null  float64\n",
            " 14  test_3          64788 non-null  float64\n",
            " 15  test_4          64788 non-null  float64\n",
            " 16  test_5          64788 non-null  float64\n",
            " 17  test_6          64788 non-null  float64\n",
            " 18  test_7          64788 non-null  float64\n",
            " 19  test_8          64788 non-null  float64\n",
            " 20  test_9          64788 non-null  float64\n",
            " 21  test_10         64788 non-null  float64\n",
            " 22  test_11         64788 non-null  float64\n",
            " 23  test_12         64788 non-null  float64\n",
            " 24  test_13         64788 non-null  float64\n",
            " 25  test_14         64788 non-null  float64\n",
            " 26  test_15         64788 non-null  float64\n",
            " 27  test_16         64788 non-null  float64\n",
            " 28  test_17         64788 non-null  float64\n",
            " 29  test_18         64788 non-null  float64\n",
            " 30  test_19         64788 non-null  float64\n",
            " 31  Tel Aviv        64788 non-null  float64\n",
            " 32  Ashdod          64788 non-null  float64\n",
            " 33  Givatayim       64788 non-null  float64\n",
            " 34  Yahud           64788 non-null  float64\n",
            " 35  Lod             64788 non-null  float64\n",
            " 36  Or-Yehuda       64788 non-null  float64\n",
            " 37  Yavne           64788 non-null  float64\n",
            " 38  Holon           64788 non-null  float64\n",
            " 39  Jerusalem       64788 non-null  float64\n",
            " 40  Rehovot         64788 non-null  float64\n",
            " 41  Ness-Ziona      64788 non-null  float64\n",
            " 42  Kiriat-Ono      64788 non-null  float64\n",
            " 43  Rishon Lezion   64788 non-null  float64\n",
            " 44  Petah-Tikva     64788 non-null  float64\n",
            " 45  Bat Yam         64788 non-null  float64\n",
            " 46  Ramla           64788 non-null  float64\n",
            " 47  Ramat Gan       64788 non-null  float64\n",
            " 48  unknown HMO     64788 non-null  float64\n",
            " 49  Meuhedet        64788 non-null  float64\n",
            " 50  Maccabi         64788 non-null  float64\n",
            " 51  Clalit          64788 non-null  float64\n",
            " 52  age             64788 non-null  float64\n",
            " 53  time in system  64788 non-null  float64\n",
            "dtypes: float64(48), int64(6)\n",
            "memory usage: 27.2 MB\n"
          ]
        }
      ],
      "source": [
        "data_encoded_train.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XK2_ZamOtOXb",
        "outputId": "f98328bf-c29d-4eb1-ad4e-04c6cd79cf33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columns with NaN values:\n",
            "[]\n"
          ]
        }
      ],
      "source": [
        "nan_columns = data_encoded_train.columns[data_encoded_train.isna().any()].tolist()\n",
        "\n",
        "# Print the columns with NaN values\n",
        "print(\"Columns with NaN values:\")\n",
        "print(nan_columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ov9QkIexz_71",
        "outputId": "056be807-dc19-46ea-88bb-1d50868cbdb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 123990 entries, 0 to 123989\n",
            "Data columns (total 54 columns):\n",
            " #   Column          Non-Null Count   Dtype  \n",
            "---  ------          --------------   -----  \n",
            " 0   gender          123990 non-null  int64  \n",
            " 1   height          123990 non-null  float64\n",
            " 2   bmi             123990 non-null  float64\n",
            " 3   heart_rate      123990 non-null  float64\n",
            " 4   steps_day_1     123990 non-null  int64  \n",
            " 5   steps_day_2     123990 non-null  float64\n",
            " 6   steps_day_3     123990 non-null  int64  \n",
            " 7   steps_day_4     123990 non-null  int64  \n",
            " 8   steps_day_5     123990 non-null  int64  \n",
            " 9   employment      123990 non-null  int64  \n",
            " 10  weight          123990 non-null  float64\n",
            " 11  test_0          123990 non-null  float64\n",
            " 12  test_1          123990 non-null  float64\n",
            " 13  test_2          123990 non-null  float64\n",
            " 14  test_3          123990 non-null  float64\n",
            " 15  test_4          123990 non-null  float64\n",
            " 16  test_5          123990 non-null  float64\n",
            " 17  test_6          123990 non-null  float64\n",
            " 18  test_7          123990 non-null  float64\n",
            " 19  test_8          123990 non-null  float64\n",
            " 20  test_9          123990 non-null  float64\n",
            " 21  test_10         123990 non-null  float64\n",
            " 22  test_11         123990 non-null  float64\n",
            " 23  test_12         123990 non-null  float64\n",
            " 24  test_13         123990 non-null  float64\n",
            " 25  test_14         123990 non-null  float64\n",
            " 26  test_15         123990 non-null  float64\n",
            " 27  test_16         123990 non-null  float64\n",
            " 28  test_17         123990 non-null  float64\n",
            " 29  test_18         123990 non-null  float64\n",
            " 30  test_19         123990 non-null  float64\n",
            " 31  Tel Aviv        123990 non-null  float64\n",
            " 32  Ashdod          123990 non-null  float64\n",
            " 33  Givatayim       123990 non-null  float64\n",
            " 34  Yahud           123990 non-null  float64\n",
            " 35  Lod             123990 non-null  float64\n",
            " 36  Or-Yehuda       123990 non-null  float64\n",
            " 37  Yavne           123990 non-null  float64\n",
            " 38  Holon           123990 non-null  float64\n",
            " 39  Jerusalem       123990 non-null  float64\n",
            " 40  Rehovot         123990 non-null  float64\n",
            " 41  Ness-Ziona      123990 non-null  float64\n",
            " 42  Kiriat-Ono      123990 non-null  float64\n",
            " 43  Rishon Lezion   123990 non-null  float64\n",
            " 44  Petah-Tikva     123990 non-null  float64\n",
            " 45  Bat Yam         123990 non-null  float64\n",
            " 46  Ramla           123990 non-null  float64\n",
            " 47  Ramat Gan       123990 non-null  float64\n",
            " 48  unknown HMO     123990 non-null  float64\n",
            " 49  Meuhedet        123990 non-null  float64\n",
            " 50  Maccabi         123990 non-null  float64\n",
            " 51  Clalit          123990 non-null  float64\n",
            " 52  age             123990 non-null  float64\n",
            " 53  time in system  123990 non-null  float64\n",
            "dtypes: float64(48), int64(6)\n",
            "memory usage: 51.1 MB\n"
          ]
        }
      ],
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "\n",
        "# Perform undersampling on the majority class\n",
        "\n",
        "# Perform oversampling on the minority class\n",
        "\n",
        "smote = SMOTE(sampling_strategy='minority') # or 'minority'\n",
        "  # You can adjust the sampling_strategy as needed\n",
        "\n",
        "# Apply SMOTE to oversample the data\n",
        "x_balanced_train, y_balanced_train = smote.fit_resample(data_encoded_train, target_train)\n",
        "# Step 1: Install XGBoost (if not already installed)\n",
        "# Step 2: Import necessary librarie\n",
        "\n",
        "x_balanced_train.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbfK0Hs3w3Er",
        "outputId": "3b49ed9a-dca3-4879-833d-b3f71f19233a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 123990 entries, 0 to 123989\n",
            "Data columns (total 54 columns):\n",
            " #   Column          Non-Null Count   Dtype  \n",
            "---  ------          --------------   -----  \n",
            " 0   gender          123990 non-null  int64  \n",
            " 1   height          123990 non-null  float64\n",
            " 2   bmi             123990 non-null  float64\n",
            " 3   heart_rate      123990 non-null  float64\n",
            " 4   steps_day_1     123990 non-null  int64  \n",
            " 5   steps_day_2     123990 non-null  float64\n",
            " 6   steps_day_3     123990 non-null  int64  \n",
            " 7   steps_day_4     123990 non-null  int64  \n",
            " 8   steps_day_5     123990 non-null  int64  \n",
            " 9   employment      123990 non-null  int64  \n",
            " 10  weight          123990 non-null  float64\n",
            " 11  test_0          123990 non-null  float64\n",
            " 12  test_1          123990 non-null  float64\n",
            " 13  test_2          123990 non-null  float64\n",
            " 14  test_3          123990 non-null  float64\n",
            " 15  test_4          123990 non-null  float64\n",
            " 16  test_5          123990 non-null  float64\n",
            " 17  test_6          123990 non-null  float64\n",
            " 18  test_7          123990 non-null  float64\n",
            " 19  test_8          123990 non-null  float64\n",
            " 20  test_9          123990 non-null  float64\n",
            " 21  test_10         123990 non-null  float64\n",
            " 22  test_11         123990 non-null  float64\n",
            " 23  test_12         123990 non-null  float64\n",
            " 24  test_13         123990 non-null  float64\n",
            " 25  test_14         123990 non-null  float64\n",
            " 26  test_15         123990 non-null  float64\n",
            " 27  test_16         123990 non-null  float64\n",
            " 28  test_17         123990 non-null  float64\n",
            " 29  test_18         123990 non-null  float64\n",
            " 30  test_19         123990 non-null  float64\n",
            " 31  Tel Aviv        123990 non-null  float64\n",
            " 32  Ashdod          123990 non-null  float64\n",
            " 33  Givatayim       123990 non-null  float64\n",
            " 34  Yahud           123990 non-null  float64\n",
            " 35  Lod             123990 non-null  float64\n",
            " 36  Or-Yehuda       123990 non-null  float64\n",
            " 37  Yavne           123990 non-null  float64\n",
            " 38  Holon           123990 non-null  float64\n",
            " 39  Jerusalem       123990 non-null  float64\n",
            " 40  Rehovot         123990 non-null  float64\n",
            " 41  Ness-Ziona      123990 non-null  float64\n",
            " 42  Kiriat-Ono      123990 non-null  float64\n",
            " 43  Rishon Lezion   123990 non-null  float64\n",
            " 44  Petah-Tikva     123990 non-null  float64\n",
            " 45  Bat Yam         123990 non-null  float64\n",
            " 46  Ramla           123990 non-null  float64\n",
            " 47  Ramat Gan       123990 non-null  float64\n",
            " 48  unknown HMO     123990 non-null  float64\n",
            " 49  Meuhedet        123990 non-null  float64\n",
            " 50  Maccabi         123990 non-null  float64\n",
            " 51  Clalit          123990 non-null  float64\n",
            " 52  age             123990 non-null  float64\n",
            " 53  time in system  123990 non-null  float64\n",
            "dtypes: float64(48), int64(6)\n",
            "memory usage: 51.1 MB\n"
          ]
        }
      ],
      "source": [
        "x_balanced_train.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qy52ERGZNY3A",
        "outputId": "99f70194-0d9a-41c4-8f17-3aa8b9aaa88e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        gender      height        bmi  heart_rate  steps_day_1  steps_day_2  \\\n",
            "0            1  169.297164  25.948374   61.600474           96    81.000000   \n",
            "1            1  171.637016  23.463067   57.429018           50    22.000000   \n",
            "2            0  159.409745  23.600005   80.609092          280    86.000000   \n",
            "3            0  159.414989  24.070889   89.218106          277   354.000000   \n",
            "4            1  180.876301  25.322567   68.951826          531   441.000000   \n",
            "...        ...         ...        ...         ...          ...          ...   \n",
            "123985       0  171.979855  14.789812   89.251378          750   689.741105   \n",
            "123986       0  146.071688  26.346295   58.092176          882   796.404955   \n",
            "123987       0  156.438878  14.585127   64.973114          802   462.450409   \n",
            "123988       0  165.474884  23.624004   78.712511         1491  1408.148952   \n",
            "123989       1  170.318170  18.286994   81.209462          670   571.043973   \n",
            "\n",
            "        steps_day_3  steps_day_4  steps_day_5  employment  ...  Bat Yam  \\\n",
            "0                49           62           63           3  ...      1.0   \n",
            "1                25           28           23           2  ...      0.0   \n",
            "2               196          272          305           0  ...      0.0   \n",
            "3               423          678          654           4  ...      0.0   \n",
            "4               346          273          374           3  ...      0.0   \n",
            "...             ...          ...          ...         ...  ...      ...   \n",
            "123985          704          265          563           2  ...      0.0   \n",
            "123986          256          263          594           2  ...      0.0   \n",
            "123987          348          319          252           0  ...      0.0   \n",
            "123988          866          754          234           2  ...      0.0   \n",
            "123989          380          338          199           2  ...      0.0   \n",
            "\n",
            "        Ramla  Ramat Gan  unknown HMO  Meuhedet   Maccabi    Clalit  \\\n",
            "0         0.0        0.0     0.000000  0.000000  0.000000  1.000000   \n",
            "1         0.0        0.0     0.000000  0.000000  1.000000  0.000000   \n",
            "2         0.0        0.0     0.000000  0.000000  0.000000  1.000000   \n",
            "3         1.0        0.0     0.000000  0.000000  0.000000  1.000000   \n",
            "4         0.0        0.0     0.000000  0.000000  1.000000  0.000000   \n",
            "...       ...        ...          ...       ...       ...       ...   \n",
            "123985    0.0        0.0     0.229018  0.000000  0.000000  0.770982   \n",
            "123986    0.0        0.0     0.000000  0.931287  0.000000  0.068713   \n",
            "123987    0.0        0.0     0.000000  0.000000  0.338568  0.661432   \n",
            "123988    0.0        0.0     0.000000  0.000000  0.000000  1.000000   \n",
            "123989    0.0        0.0     0.000000  0.020783  0.000000  0.979217   \n",
            "\n",
            "              age  time in system  label  \n",
            "0       58.100905        4.074896      0  \n",
            "1       54.511583        2.829174      0  \n",
            "2       77.353472        4.671747      0  \n",
            "3       85.052308        5.274074      0  \n",
            "4       58.763465        4.600563      0  \n",
            "...           ...             ...    ...  \n",
            "123985  27.136985        3.782413      1  \n",
            "123986  71.741452        2.264852      1  \n",
            "123987  92.641365        3.294019      1  \n",
            "123988  40.451908        2.218062      1  \n",
            "123989  66.647231        4.009181      1  \n",
            "\n",
            "[123990 rows x 55 columns]\n",
            "label          1.000000\n",
            "gender         0.501157\n",
            "age            0.351869\n",
            "employment     0.266508\n",
            "steps_day_5    0.253067\n",
            "test_1         0.236446\n",
            "test_8         0.203154\n",
            "test_19        0.201485\n",
            "test_16        0.182944\n",
            "steps_day_1    0.180458\n",
            "Name: label, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# Merge the target DataFrame back to the original DataFrame\n",
        "merged_df =  pd.concat([x_balanced_train, y_balanced_train ], axis=1)\n",
        "\n",
        "print(merged_df)\n",
        "\n",
        "correlation_matrix = merged_df.corr()\n",
        "correlation_with_target = correlation_matrix['label'].abs()\n",
        "sorted_features = correlation_with_target.sort_values(ascending=False)\n",
        "\n",
        "top_5_features = sorted_features[:10]\n",
        "print(top_5_features)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3h7GjOf3Tdky",
        "outputId": "c42a7137-3173-429c-d8de-a287f63b09c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Outlier indices: [    0     1     2 ... 15944 15945 15946]\n",
            "18751\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:3472: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
            "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "def identify_outliers_zscore(data, threshold=3):\n",
        "    z_scores = np.abs((data - np.mean(data)) / np.std(data))\n",
        "    outliers = np.where(z_scores > threshold)[0]\n",
        "    return outliers\n",
        "\n",
        "# Assuming you have your data in a NumPy array called 'data'\n",
        "outliers = identify_outliers_zscore(data_encoded_test)\n",
        "\n",
        "# Print the indices of the outliers\n",
        "print(\"Outlier indices:\", outliers)\n",
        "print(len(outliers))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vDGcUEIauUzH"
      },
      "outputs": [],
      "source": [
        "importent_features =['age','F','employment','steps_day_5','test_1','test_8','test_19']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FdnriC6CE0eU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THOXUzxv4Slw",
        "outputId": "17f7f61d-0038-4bcf-f3f6-7d6f9caa3fe9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.944691791559541\n",
            "['bmi', 'gender', 'weight', 'height', 'age', 'Clalit', 'Meuhedet', 'Maccabi', 'employment', 'unknown HMO']\n",
            "             bmi  gender      weight      height        age  Clalit  Meuhedet  \\\n",
            "0      20.828150       1   62.736860  173.554565  28.140604     1.0       0.0   \n",
            "1      21.883287       1   70.567368  179.574921  37.356210     1.0       0.0   \n",
            "2      27.364812       0   64.929900  154.037383  46.766203     0.0       0.0   \n",
            "3      28.599989       0   67.583930  160.083594  77.966751     0.0       0.0   \n",
            "4      29.835165       1   90.973039  174.619254  28.901727     0.0       1.0   \n",
            "...          ...     ...         ...         ...        ...     ...       ...   \n",
            "15942  22.724816       1   69.188568  174.488570  40.252856     1.0       0.0   \n",
            "15943  17.509075       0   48.277615  166.050928  93.512267     1.0       0.0   \n",
            "15944  27.447761       0   68.291875  157.736084  51.067367     1.0       0.0   \n",
            "15945  24.330192       1   72.968513  173.178901  23.812062     0.0       0.0   \n",
            "15946  39.107082       1  120.448232  175.498135  75.650529     1.0       0.0   \n",
            "\n",
            "       Maccabi  employment  unknown HMO  \n",
            "0          0.0           1          0.0  \n",
            "1          0.0           2          0.0  \n",
            "2          0.0           4          1.0  \n",
            "3          0.0           2          1.0  \n",
            "4          0.0           1          0.0  \n",
            "...        ...         ...          ...  \n",
            "15942      0.0           4          0.0  \n",
            "15943      0.0           0          0.0  \n",
            "15944      0.0           3          0.0  \n",
            "15945      1.0           0          0.0  \n",
            "15946      0.0           2          0.0  \n",
            "\n",
            "[15947 rows x 10 columns]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "selected_features = ['gender', 'bmi', 'weight', 'Clalit', 'age', 'Meuhedet', 'height', 'Maccabi', 'unknown HMO', 'employment']\n",
        "\n",
        "x_train  = x_balanced_train[selected_features]\n",
        "x_test =  data_encoded_test[selected_features]\n",
        "y_train = y_balanced_train\n",
        "y_test = target_test\n",
        "\n",
        "# Create a Random Forest classifier object\n",
        "rf_model = RandomForestClassifier()\n",
        "#max_depth = None ,min_samples_leaf= 4,criterion= 'entropy'\n",
        "\n",
        "# Train the model on the training data\n",
        "rf_model.fit(x_train, y_train)\n",
        "\n",
        "# Use the trained model to make predictions on the test data\n",
        "y_pred = rf_model.predict(x_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "feature_importances = rf_model.feature_importances_\n",
        "\n",
        "# Sort feature importances in descending order\n",
        "indices = np.argsort(feature_importances)[::-1]\n",
        "\n",
        "# Select the top K features or define a threshold\n",
        "top_k = 10\n",
        "selected_features = x_train.columns[indices[:top_k]]\n",
        "\n",
        "k_train_selected = x_train[selected_features]\n",
        "k_test_selected = x_test[selected_features]\n",
        "print(k_train_selected.columns.tolist())\n",
        "print(k_test_selected)\n",
        "def create_submission_file(filename, model, test_data, Ids):\n",
        "    predictions = model.predict_proba(x_test)[:, 1]\n",
        "    my_submission = pd.DataFrame({'patient_id': Ids, 'prediction': predictions})\n",
        "    my_submission.to_csv(filename, index=False)\n",
        "create_submission_file(\"mysubmission-random forest__balanced__with_selection_witg_fine_tuning_with_probabilites.csv\", rf_model,x_train,test_ids)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iiyDRylmSnGC",
        "outputId": "17e0af08-60c3-43c0-ac66-30f95fbefdca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_feature: {'max_features': 'sqrt'}\n"
          ]
        }
      ],
      "source": [
        "param_grid = {\n",
        "    'max_features': ['auto', 'sqrt'],\n",
        "}\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Assuming you have your features in X and target variable in y\n",
        "#rf_model = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Create a GridSearchCV object\n",
        "grid_search = GridSearchCV(rf_model, param_grid, cv=5, scoring='roc_auc')\n",
        "\n",
        "# Fit the GridSearchCV object to the data\n",
        "grid_search.fit(x_train, y_train)\n",
        "\n",
        "# Retrieve the best hyperparameters found by GridSearchCV\n",
        "best_params = grid_search.best_params_\n",
        "print('max_feature:', best_params)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lBB84vYjSabC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DNnFlTb-Sa80"
      },
      "outputs": [],
      "source": [
        "#n_estimators = 300 , Bestmax_depth: {'max_depth': None} ,max_feature: {'max_features': 'auto'} ,'min_samples_leaf': 1,gini }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pemcIyz0SbHO",
        "outputId": "d864e965-8108-4374-a14b-5fee08030c9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bestmax_depth: {'max_depth': None}\n"
          ]
        }
      ],
      "source": [
        "param_grid = {\n",
        "    'max_depth': [None, 5, 10],\n",
        "}\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Assuming you have your features in X and target variable in y\n",
        "#rf_model = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Create a GridSearchCV object\n",
        "grid_search = GridSearchCV(rf_model, param_grid, cv=5, scoring='roc_auc')\n",
        "\n",
        "# Fit the GridSearchCV object to the data\n",
        "grid_search.fit(x_train, y_train)\n",
        "\n",
        "# Retrieve the best hyperparameters found by GridSearchCV\n",
        "best_params = grid_search.best_params_\n",
        "print(\"Bestmax_depth:\", best_params)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KlRoPSJHSbeh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4xFRfAcSj0w",
        "outputId": "f4228cc9-a77c-4c7c-eefd-b6a0a0435ab5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "min samples leaf: {'min_samples_leaf': 2}\n"
          ]
        }
      ],
      "source": [
        "param_grid = {\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "}\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Assuming you have your features in X and target variable in y\n",
        "#rf_model = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Create a GridSearchCV object\n",
        "grid_search = GridSearchCV(rf_model, param_grid, cv=5, scoring='roc_auc')\n",
        "\n",
        "# Fit the GridSearchCV object to the data\n",
        "grid_search.fit(x_train, y_train)\n",
        "\n",
        "# Retrieve the best hyperparameters found by GridSearchCV\n",
        "best_params = grid_search.best_params_\n",
        "print(\"min samples leaf:\", best_params)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mHG55iSvS2dR",
        "outputId": "e34fa284-8eb9-4ebb-f467-f71ca2e5fa8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "criterion: {'criterion': 'entropy'}\n"
          ]
        }
      ],
      "source": [
        "param_grid = {\n",
        "    'criterion': ['gini', 'entropy']\n",
        "}\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Assuming you have your features in X and target variable in y\n",
        "#rf_model = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Create a GridSearchCV object\n",
        "grid_search = GridSearchCV(rf_model, param_grid, cv=5, scoring='roc_auc')\n",
        "\n",
        "# Fit the GridSearchCV object to the data\n",
        "grid_search.fit(x_train, y_train)\n",
        "\n",
        "# Retrieve the best hyperparameters found by GridSearchCV\n",
        "best_params = grid_search.best_params_\n",
        "print(\"criterion:\", best_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z0stvIKlSm7v"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aL8tmQyw6JPW",
        "outputId": "40eb03b1-6b9c-4fbd-cba7-f23a38000438"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_estimators= 300\n"
          ]
        }
      ],
      "source": [
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300]  # Example values to try\n",
        "}\n",
        "\n",
        "# Perform grid search with cross-validation\n",
        "grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, scoring='roc_auc', cv=5)\n",
        "grid_search.fit(x_train,y_train)\n",
        "# Get the best parameter combination\n",
        "best_colsample_bytree = grid_search.best_params_['n_estimators']\n",
        "print(\"n_estimators=\", best_colsample_bytree)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3sY-wly8GQ_0"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "selected_features = ['gender', 'bmi', 'weight', 'Clalit', 'age', 'Meuhedet', 'height', 'Maccabi', 'unknown HMO', 'steps_day_5']\n",
        "\n",
        "x_train  = x_balanced_train\n",
        "x_test =  data_encoded_test\n",
        "y_train = y_balanced_train\n",
        "y_test = target_test\n",
        "\n",
        "# Create a Random Forest classifier object\n",
        "rf_model = RandomForestClassifier()\n",
        "    #n_estimators = 300 , max_depth = None  , min_samples_leaf= 1,criterion = 'gini'\n",
        "\n",
        "# Train the model on the training data\n",
        "rf_model.fit(x_train, y_train)\n",
        "\n",
        "# Use the trained model to make predictions on the test data\n",
        "y_pred = rf_model.predict(x_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "\n",
        "feature_importances = rf_model.feature_importances_\n",
        "\n",
        "# Sort feature importances in descending order\n",
        "indices = np.argsort(feature_importances)[::-1]\n",
        "\n",
        "# Select the top K features or define a threshold\n",
        "top_k = 10\n",
        "selected_features = x_train.columns[indices[:top_k]]\n",
        "\n",
        "k_train_selected = x_train[selected_features]\n",
        "k_test_selected = x_test[selected_features]\n",
        "print(k_train_selected.columns.tolist())\n",
        "print(k_test_selected)\n",
        "def create_submission_file(filename, model, test_data, Ids):\n",
        "    predictions = model.predict_proba(x_test)[:, 1]\n",
        "    my_submission = pd.DataFrame({'patient_id': Ids, 'prediction': predictions})\n",
        "    my_submission.to_csv(filename, index=False)\n",
        "create_submission_file(\"mysubmission-random forest__balanced__with_selection_witg_fine_tuning_with_probabilites.csv\", rf_model,x_train,test_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "PK4QgsUOSboR"
      },
      "outputs": [],
      "source": [
        "para_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [None, 5, 10],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'max_features': ['auto', 'sqrt'],\n",
        "    'criterion': ['gini', 'entropy']\n",
        "\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Assuming you have your features in X and target variable in y\n",
        "#rf_model = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Create a GridSearchCV object\n",
        "grid_search = GridSearchCV(rf_model, param_grid, cv=5, scoring='roc_auc')\n",
        "\n",
        "# Fit the GridSearchCV object to the data\n",
        "grid_search.fit(x_train, y_train)\n",
        "\n",
        "# Retrieve the best hyperparameters found by GridSearchCV\n",
        "best_params = grid_search.best_params_\n",
        "print(\"Best parameters:\", best_params)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "adxSfLNC_D8l"
      },
      "outputs": [],
      "source": [
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [None, 5, 10],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'max_features': ['auto', 'sqrt'],\n",
        "    'criterion': ['gini', 'entropy']\n",
        "}\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Assuming you have your features in X and target variable in y\n",
        "#rf_model = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Create a GridSearchCV object\n",
        "grid_search = GridSearchCV(rf_model, param_grid, cv=5, scoring='accuracy')\n",
        "\n",
        "# Fit the GridSearchCV object to the data\n",
        "grid_search.fit(x_train, y_train)\n",
        "\n",
        "# Retrieve the best hyperparameters found by GridSearchCV\n",
        "best_params = grid_search.best_params_\n",
        "print(\"Best parameters:\", best_params)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "36qng-WK6OKD"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "param_grid = {\n",
        "    'max_depth': [3, 5, 7]  # Example values to try\n",
        "}\n",
        "\n",
        "# Perform grid search with cross-validation\n",
        "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, scoring='roc_auc', cv=5)\n",
        "grid_search.fit(x_train,y_train)\n",
        "\n",
        "# Get the best parameter combination\n",
        "best_max_depth = grid_search.best_params_['max_depth']\n",
        "print(\"max_depth=\", best_max_depth)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BTOrNbelPn2G"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0zIeKu2D9jXq"
      },
      "outputs": [],
      "source": [
        "selected features = ['M', 'bmi', 'F', 'weight', 'Clalit', 'age', 'height', 'Maccabi', 'Meuhedet', 'unknown HMO']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MBJ6eNOY-KX7"
      },
      "outputs": [],
      "source": [
        "feature1 = x_balanced_train['F']\n",
        "feature2 = x_balanced_train['M']\n",
        "\n",
        "# Calculate the correlation coefficient between the two features\n",
        "correlation = feature1.corr(feature2)\n",
        "\n",
        "# Print the correlation coefficient\n",
        "print(\"Correlation coefficient:\", correlation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PRXzTBayUyut"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "\n",
        "x1_train, x1_val, y1_train, y1_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "# Create a Random Forest classifier object\n",
        "rf_model = RandomForestClassifier(n_estimators = 300 , max_depth = None  , min_samples_leaf= 1,criterion = 'gini' )\n",
        "\n",
        "# Train the model on the training data\n",
        "rf_model.fit(x1_train, y1_train)\n",
        "\n",
        "# Use the trained model to make predictions on the test data\n",
        "y_pred = rf_model.predict(x1_val)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "\n",
        "feature_importances = rf_model.feature_importances_\n",
        "\n",
        "# Sort feature importances in descending order\n",
        "indices = np.argsort(feature_importances)[::-1]\n",
        "\n",
        "# Select the top K features or define a threshold\n",
        "top_k = 10\n",
        "selected_features = x_train.columns[indices[:top_k]]\n",
        "\n",
        "x_train_selected = x_train[selected_features]\n",
        "x_test_selected = x_test[selected_features]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZ2cpE7bFR4a"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}